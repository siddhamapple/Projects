{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOROA3nNbgClDqDo1nxzdf/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddhamapple/Projects/blob/main/Meeting_audio_to_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9ojk1GaXr_3"
      },
      "outputs": [],
      "source": [
        "pip install moviepy vosk pydub soundfile\n",
        "# Importing required libraries\n",
        "import os\n",
        "import subprocess\n",
        "import wave\n",
        "import json\n",
        "from vosk import Model, KaldiRecognizer\n",
        "import moviepy.editor as mp\n",
        "\n",
        "# Function to setup FFmpeg and configure Pydub to use it\n",
        "def setup_ffmpeg(ffmpeg_dir):\n",
        "    # Path to ffmpeg executable\n",
        "    ffmpeg_path = os.path.join(ffmpeg_dir, \"ffmpeg.exe\")\n",
        "    ffprobe_path = os.path.join(ffmpeg_dir, \"ffprobe.exe\")\n",
        "    ffplay_path = os.path.join(ffmpeg_dir, \"ffplay.exe\")\n",
        "\n",
        "    if not os.path.exists(ffmpeg_path):\n",
        "        raise FileNotFoundError(f\"FFmpeg not found at {ffmpeg_path}\")\n",
        "\n",
        "    # Return paths for ffmpeg executables\n",
        "    return ffmpeg_path, ffprobe_path, ffplay_path\n",
        "# Setup FFmpeg and get the paths to executables\n",
        "ffmpeg_path, ffprobe_path, ffplay_path = setup_ffmpeg(ffmpeg_directory)\n",
        "print(f\"FFmpeg configured at: {ffmpeg_path}\")\n",
        "\n",
        "model_path = r\"C:\\Users\\Ritika.Gupta\\Downloads\\vosk\"\n",
        "video_path = r\"C:\\Users\\Ritika.Gupta\\Downloads\\MIDAS_UiPath_Process_20240603.mp4\"\n",
        "audio_output_path = r\"C:\\Users\\Ritika.Gupta\\Downloads\\MIDAS_UiPath_Process_20240603.wav\"\n",
        "# Function to extract audio from video using ffmpeg\n",
        "def extract_audio_from_video(ffmpeg_path, video_path, audio_output_path):\n",
        "    try:\n",
        "        # Use ffmpeg to extract audio\n",
        "        ffmpeg_command = [\n",
        "            ffmpeg_path,\n",
        "            \"-i\", video_path,  # Input video file\n",
        "            \"-vn\",  # No video\n",
        "            \"-acodec\", \"pcm_s16le\",  # Audio codec: PCM signed 16-bit little-endian\n",
        "            \"-ac\", \"1\",  # Audio channels: mono\n",
        "            \"-ar\", \"16000\",  # Audio sampling rate: 16kHz\n",
        "            \"-y\",  # Overwrite output file if it exists\n",
        "            audio_output_path  # Output audio file\n",
        "        ]\n",
        "        subprocess.run(ffmpeg_command, check=True)\n",
        "        print(f\"Audio extracted to {audio_output_path}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error during audio extraction with ffmpeg: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error during audio extraction: {e}\")\n",
        "\n",
        "# Function to transcribe audio to text using Vosk\n",
        "def transcribe_audio(audio_path, model_path):\n",
        "    try:\n",
        "        if not os.path.exists(model_path):\n",
        "            print(\"Please download the Vosk model for English with Indian accent from https://alphacephei.com/vosk/models.\")\n",
        "            return None\n",
        "\n",
        "        model = Model(model_path)\n",
        "        recognizer = KaldiRecognizer(model, 16000)\n",
        "\n",
        "        wf = wave.open(audio_path, \"rb\")\n",
        "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() != 16000:\n",
        "            print(\"Audio file must be WAV format mono PCM at 16kHz\")\n",
        "            return None\n",
        "\n",
        "        transcription = \"\"\n",
        "\n",
        "        while True:\n",
        "            data = wf.readframes(4000)\n",
        "            if len(data) == 0:\n",
        "                break\n",
        "            if recognizer.AcceptWaveform(data):\n",
        "                result = json.loads(recognizer.Result())\n",
        "                transcription += result['text'] + \" \"\n",
        "\n",
        "        final_result = json.loads(recognizer.FinalResult())\n",
        "        transcription += final_result['text']\n",
        "\n",
        "        return transcription\n",
        "    except Exception as e:\n",
        "        print(f\"Error during transcription: {e}\")\n",
        "        return None\n",
        "# Extract audio from video\n",
        "extract_audio_from_video(ffmpeg_path, video_path, audio_output_path)\n",
        "# Transcribe the extracted audio\n",
        "transcription_text = transcribe_audio(audio_output_path, model_path)\n",
        "if transcription_text:\n",
        "    print(\"Transcription Text:\")\n",
        "    print(transcription_text)\n",
        "else:\n",
        "    print(\"No transcription generated.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "MTSL internship project\n",
        "The code facilitates the conversion of a meeting video into text by extracting audio using FFmpeg, a powerful multimedia framework.\n",
        " It converts the video’s audio track to a mono WAV file with a specific format (16kHz, PCM 16-bit).\n",
        "  The Vosk library is then employed to transcribe the audio: it processes the audio in chunks, recognizing speech and converting it into text.\n",
        "  This is achieved by reading audio data, running it through Vosk’s speech recognition model, and appending the recognized text to a transcription.\n",
        "   The result is a text document that captures the dialogue from the video.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "94NU4_POX_uP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}